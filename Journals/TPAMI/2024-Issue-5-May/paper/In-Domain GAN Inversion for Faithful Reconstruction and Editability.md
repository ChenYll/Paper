# 题目：[In-Domain GAN Inversion for Faithful Reconstruction and Editability](https://ieeexplore.ieee.org/document/10418542/)  
## 领域内GAN反演：用于精确重建和可编辑性
**作者：Jiapeng Zhu, Yujun Shen, Yinghao Xu, Deli Zhao, Qifeng Chen, and Bolei Zhou,** 


## 摘要
生成对抗网络（GANs）通过将随机采样的潜在代码映射到高保真合成图像，显著推进了图像合成技术。然而，将训练良好的GAN应用于真实图像编辑仍然具有挑战性。一个常见的解决方案是找到一个近似的潜在代码，能够充分恢复输入图像以进行编辑，这也被称为GAN反演。为了反演GAN模型，先前的工作通常专注于在像素级重建目标图像，但很少有研究涉及反演结果是否能够很好地支持语义级别的操作。本工作通过提出领域引导的GAN反演来填补这一空白，该方法包括一个领域引导的编码器和一个领域正则化优化器，以在预训练的GAN模型的原始潜在空间中正则化反演代码。通过这种方式，我们成功地充分利用了GAN学习的知识进行图像重建，从而在不进行任何重新训练的情况下促进了广泛的编辑应用。我们进一步对编码器结构、起始反演点以及反演参数空间的影响进行了全面分析，并观察到重建质量和编辑属性之间的权衡。这种权衡揭示了GAN模型如何表示具有各种语义编码在潜在分布中的图像。

## 关键词
- 生成对抗网络 (GAN)
- GAN反演
- 图像编辑

# I. 引言
生成对抗网络（GANs）的快速发展已经使得在高分辨率下合成逼真的图像成为可能。GANs的公式化方法使得生成器通过随机采样预定义的潜在分布来重现观测到的数据分布。现有工作已经确认，在学习将潜在代码映射到合成图像的过程中，GANs自发地编码了多样的变化因素到潜在空间中。每个变化因素都表现为一个可解释的方向，以至于沿着某个特定方向移动潜在代码可以导致输出图像关于某个特定属性的编辑。然而，由于GAN缺乏推理能力，这种潜在空间的操作能力很难应用于真实图像。
为了弥合这一差距，许多尝试已经被做出来逆转GANs的生成过程，这被广泛称为GAN反演。现有的研究通常专注于重建目标图像的像素值，但很少有研究关注反演代码是否支持像从原始潜在空间中采样的潜在代码那样的满意操作。因此，对于反演结果的编辑属性，即我们所说的潜在代码的可编辑性，没有保证，导致在实践中的应用受到限制。


理想情况下，一个好的GAN反演方法不仅应该从像素级恢复输入图像，更重要的是，从语义级恢复。只有这样，我们才能重用GAN学习到的知识（即，潜在空间中编码的变化因素）来操作输入，这是GAN反演的后续目标。为此，我们提出在生成器的原始潜在空间内正则化反演代码，而不是简单地重建每个像素值。我们称生成的代码为领域内代码，因为它与预训练的GAN模型中出现的语义领域一致。具体来说，我们首先训练一个领域引导的编码器，将图像空间投影回潜在空间，以便编码器生成的所有代码都在领域内。然后我们提出一个领域正则化的优化器，通过将编码器作为一个正则化器来调整反演代码，以更好地重建像素值，同时不影响编辑属性。得益于我们的领域内反演流程，我们称之为IDInvert，我们能够在视觉上和语义上基于训练良好的GAN模型表示目标图像，从而促进各种下游编辑任务。


我们进一步深入分析了所提出的方法，探索了不同设计选择如何影响反演性能。首先，我们发现，与模型结构和学习能力相比，编码器的训练方式对反演代码的属性更为重要。因此，可以使用轻量级编码器来加速反演过程。其次，我们确认选择一个适当的起始点（即，作为反演的归纳偏置的初始潜在代码）显著降低了编码器的训练难度。第三，我们研究了反演空间维度的影响，并观察到重建质量和编辑属性之间的明显权衡。具体来说，扩大参数空间可以使图像恢复更加准确，但另一方面，它削弱了反演代码与预训练GAN模型学习到的潜在语义之间的对齐。换句话说，我们总是可以使用一个学习良好的生成器来过度拟合一个图像，然而，只有语义上有意义的表示（即，反演）才能支持操作。
这项工作的初步结果发表在[17]中。在这篇期刊扩展中，我们增加了以下新内容：i) 在第V-A节中对编码器架构进行了详细研究，表明编码器的学习方式比其模型容量更重要；ii) 在第V-B节中对编码器学习进行初始反演点的分析，表明一个好的起始点显著降低了训练难度，因此得到了更好的收敛；iii) 基于上述分析，提出了一种改进的解决方案，使我们的方法与StyleGAN2[3]兼容；iv) 在第VI节中对GAN反演任务中重建质量和编辑属性之间的权衡进行了详尽的调查，包括v) 讨论我们是否应该用更大的潜在空间重新训练生成器；vi) 分析了通过噪声空间扩展反演空间的影响。

# III. 领域内GAN反演

如上所述，除了通过像素值恢复输入图像之外，我们还关心在反演GAN模型时，反演代码是否在语义上有意义。这里的语义指的是GAN从观测数据中学习到的涌现知识。为此，我们提出首先训练一个领域引导的编码器，然后使用这个编码器作为进一步领域正则化优化的正则化器，如图1所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/c34e10e3546849e0ba159497c3d20bb5.jpeg" width="70%" />
</div>

## 问题陈述
在详细介绍之前，我们简要介绍问题设置和一些基本符号。一个GAN模型通常由一个生成器 $G(\cdot): Z \rightarrow X$ 组成，用于合成高质量图像，以及一个鉴别器 $D(\cdot)$ 用于区分真实和合成数据。GAN反演研究了 $G(\cdot)$ 的反向映射，即找到最佳的潜在代码 $z_ {inv}$ 来恢复给定的真实图像 $x_ {real}$。我们称GAN学习到的语义空间为 $S$。我们希望 $z_ {inv}$ 也与预训练GAN模型中的先验知识 $S$ 对齐。

## 潜在空间的选择
通常，GANs从预定义的分布空间 $Z$（如正态分布）中采样潜在代码 $z$。最近的StyleGAN模型提出首先将初始潜在空间 $Z$ 映射到第二个潜在空间 $W$，然后输入代码 $w \in W$ 到生成器进行图像合成。这种额外的映射已经被证明可以学习到更解耦的语义。因此，解耦空间 $W$ 被广泛用于GAN反演任务。同样，我们也选择 $W$ 空间作为反演空间，原因有三：i) 我们关注反演代码的语义（即，领域内）属性，使 $W$ 空间更适合分析。ii) 反演到 $W$ 空间比 $Z$ 空间表现更好。iii) 通过在生成器前简单地学习一个额外的MLP，很容易将 $W$ 空间引入到任何GAN模型中。

## A. 领域引导的编码器
训练编码器通常用于GAN反演问题，考虑到其快速的推理速度。然而，现有方法简单地学习一个确定性模型，而不关心编码器产生的代码是否与 $G(\cdot)$ 学习到的语义知识对齐。如图1(a)的顶部所示，随机采样的潜在代码 $z_ {sam}$ 被送入 $G(\cdot)$ 以获得相应的合成 $x_ {syn}$。然后，编码器 $E(\cdot)$ 将 $x_ {syn}$ 和 $z_ {sam}$ 作为输入和监督，分别通过以下方式进行训练：

$$
\min_ {\Theta_ E} L_ E = ||z_ {sam} - E(G(z_ {sam}))||^2_ 2,
$$

其中 $|| \cdot ||_ 2$ 表示 $l2$ 距离， $\Theta_ E$ 表示编码器 $E(\cdot)$ 的参数。我们认为，仅通过重建 $z_ {sam}$ 来进行监督是不足以训练一个精确的编码器的。此外，生成器实际上被忽略了，不能提供其领域知识来指导编码器的训练，因为根本不考虑来自 $G(\cdot)$ 的梯度。

为了解决这些问题，我们提出了一个领域引导的编码器的训练方法，如图1(a)的底部所示。与传统编码器相比，有三个主要区别：i) 编码器的输出被送入生成器以重建输入图像，使得目标函数来自图像空间而不是潜在空间。这涉及生成器在训练中的语义知识，并提供更信息丰富和准确的监督。因此，输出代码因此保证与生成器的语义领域对齐。ii) 与使用合成图像训练不同，领域引导的编码器使用真实图像进行训练，使我们的编码器更适用于真实应用。iii) 为了确保重建的图像足够逼真，我们使用鉴别器与编码器竞争。这样，我们可以从GAN模型中获取尽可能多的信息（即，使用GAN的两个组成部分）。对抗性训练方式也推动输出代码更好地适应生成器的语义知识。我们还引入了使用VGG提取的特征的感知损失。因此，训练过程可以被公式化为：

$$
\begin{align}
\min_ {\Theta_ E} L_ E = ||x_ {real} - G(E(x_ {real}))||^2_ 2 + \lambda_ {vgg} ||F(x_ {real}) - F(G(E(x_ {real})))||^2 - \lambda_ {adv} E[x_ {real} \sim P_ {data}][D(G(E(x_ {real})))],
\end{align}
$$

$$
\min_ {\Theta_ D} L_ D = E[x_ {real} \sim P_ {data}][D(G(E(x_ {real})))] - E[x_ {real} \sim P_ {data}][D(x_ {real})] + \gamma \cdot \frac{1}{2} E[x_ {real} \sim P_ {data}][||\nabla_ {x}D(x_ {real})||^2_ 2],
$$

其中 $P_ {data}$ 表示真实数据的分布， $\gamma$ 是梯度正则化的超参数， $\lambda_ {vgg}$ 和 $\lambda_ {adv}$ 分别是感知损失和鉴别器损失权重。 $F(\cdot)$ 表示VGG特征提取模型。值得注意的是，这种类型的重建损失在其他任务中也常用于图像到图像的翻译、图像超分辨率等，因为它能够有效地重建输入图像。

## B. 领域正则化优化
与GANs的生成过程不同，它学习从潜在分布到真实图像分布的映射，GAN反演更像是一个实例级任务，即最佳重建给定的个体图像。从这个角度来看，由于编码器的表示能力有限，很难仅用一个编码器学习到一个完美的反向映射。因此，即使由所提出的领域引导编码器反演的代码能够很好地基于预训练的生成器重建输入图像，并确保代码本身在语义上有意义，我们仍然需要细化代码，使其更好地适应目标个体图像的像素值。

先前的方法提出使用梯度下降算法来优化代码。图1(b)的顶部展示了优化过程，其中潜在代码基于生成器“自由”优化。它很可能会得到一个领域外的反演，因为对潜在代码没有任何约束。依靠我们的领域引导编码器，我们设计了一个领域正则化优化，有两个改进，如图1(b)的底部所示：i) 我们使用领域引导编码器的输出作为一个理想的起始点，这避免了代码陷入局部最小值，并显著缩短了优化过程。ii) 我们在优化过程中将领域引导编码器作为一个正则化器，以保持潜在代码在生成器的语义领域内。总结来说，优化的目标函数为：

$$
z_ {inv} = \text{arg min}_ z ||x - G(z)||^2_ 2 + \lambda_ {vgg} ||F(x) - F(G(z))||^2 + \lambda_ {dom} ||z - E(G(z))||^2_ 2,
$$

其中 $x$ 是要反演的目标图像， $\lambda_ {vgg}$ 和 $\lambda_ {dom}$ 分别是感知损失和编码器正则化器的损失权重。

# IV. 评估任务

在本节中，我们介绍用于评估我们提出方法的任务，包括其反演质量和几个图像编辑应用。但是，我们首先给出那些被评估任务的实现细节。

## A. 实现细节
我们在FFHQ数据集上进行实验，并在LSUN数据集的三个子类别上进行实验，即塔（户外场景）、教堂（户外场景）和卧室（室内场景），以评估我们提出的方法，包括领域引导的编码器和领域正则化优化。对于FFHQ，它包含了70,000张高质量的面部图像，我们按照数据集的确切顺序取前65,000张面孔作为训练集，剩余的5,000张面孔作为重建测试。对于LSUN的两个子集，我们从每个数据集的前0.6百万图像中随机抽取0.1百万图像，并从剩余的数据集中分别选择5,000张图像作为测试数据。要反演的GANs是按照StyleGAN预训练的。当训练领域引导的编码器时，生成器是固定的，我们只根据(2)和(3)更新编码器和鉴别器，并且损失权重设置为 $\lambda_ {vgg} = 5e-5$， $\lambda_ {adv} = 0.1$，并且 $\gamma = 10$。至于(2)中的感知损失，我们采用VGG[66]的输出conv4_ 3。我们为领域正则化优化设置 $\lambda_ {dom} = 2$，在第VI-A节中可以找到这个参数的消融研究。对于编码器架构，我们将在第V节中进行详细分析。对于定量评估指标，我们使用Fréchet Inception Distance (FID)、Sliced Wasserstein Distance (SWD)、均方误差 (MSE) 和结构相似性指数测量 (SSIM)。这些指标通常用于测量GANs中图像的质量。

## B. 反演质量
回想我们认为一个好的GAN反演方法不仅应该精确地恢复给定图像，而且还应该保持反演代码在语义上有意义，以便进行下游任务。因此，这部分的评估可以分为两部分。一部分是重建图像的质量，如其与输入对比的精确度和真实感。另一部分是反演代码的属性，如与边界对齐的语义。换句话说，与边界的对齐越多，我们可以获得的编辑结果就越令人满意。

### 重建图像的质量
GAN反演的主要目标是能够忠实地重建输入图像。因此，在本节中，我们评估了我们方法的重建图像质量，以及与现有基线的一些比较，包括传统的编码器[9]和基于MSE的优化[16]。图2显示了使用不同方法对人脸、塔和卧室的重建结果的比较。图2(b)和(d)之间的比较显示了我们领域引导的编码器在学习从图像空间到潜在空间的更好映射方面的优越性。图2(c)显示了与图2(d)相比，在反转给定图像时出现的模糊性。图2(e)是我们的整个算法，它展示了我们在第III-B节中介绍的优化进一步改善了重建结果。表I给出了测试数据上的定量比较结果。从表中可以看出，Image2StyleGAN[16]在SSIM和MSE方面超过了我们的方法。然而，它只关注于重建输入图像的像素，并且在重建图像的保真度和真实感方面，我们的方法大幅度超过了它（例如，参见FID和SWD指标）。此外，Image2StyleGAN反转一张图像需要太多时间。例如，它需要290秒，而我们的方法在2080 Ti GPU上反转一张图像只需要8秒。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/7a7f5ce94f4244f59cfc2add859d4f4a.jpeg" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/582cf66acf294f47a560f7bac44912cc.jpeg" width="70%" />

</div>


### 反演代码的属性
如上所述，我们的方法可以产生令人满意的重建结果。在这一部分，我们进一步评估了反演代码如何语义地表示目标图像。如先前工作[2]、[29]所指出的，GANs的潜在空间在语义上是线性可分的。特别是，对于一个二元属性（例如，男性与女性），有可能找到一个人潜在超平面，使得同一侧面的所有点对应于相同的属性。我们使用这个属性来评估反演代码与潜在语义的对齐。我们使用现成的属性分类器来预测年龄（年轻与年老）、性别（女性与男性）、眼镜（缺失与存在）和姿势（左与右）在面部测试数据集上。这些预测被视为真实情况。然后，我们使用最新的GAN反演方法，Image2StyleGAN[16]，和我们提出的领域内GAN反演，将这些图像反演回固定StyleGAN模型训练的FFHQ数据集的潜在空间。InterFaceGAN[29]用于在潜在空间中搜索上述属性的语义边界。然后，我们使用这些边界以及反演代码来评估属性分类性能。图3显示了在每个语义上的精确召回曲线。我们可以很容易地看出，我们方法反演的代码在语义上更有意义。这定量地证明了我们提出的领域内反演在保持反演代码的语义属性方面的有效性。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/6eb99b03ae294a19bb8977da0bf27966.jpeg" width="70%" />

</div>

## C. 真实图像编辑
在本节中，我们在真实图像编辑任务上评估我们的领域内GAN反演方法，包括图像插值和语义图像操作。我们还提出了一个新颖的图像编辑任务，称为语义图像扩散，以查看我们的方法如何能够将一个图像的特定部分（通常是最具代表性的部分）适应到另一个图像的上下文中，并保持结果在语义上有意义且无缝兼容。

### 图像插值
图像插值的目标是在语义上插值两个图像，这适合于研究反演代码中包含的语义。换句话说，对于一个好的反演，当插值两个反演代码时，语义应该连续变化。

图4显示了Image2StyleGAN [16]和我们的领域内反演在图像插值任务上的比较结果。我们在人脸、塔和卧室数据集上进行实验（对于人脸和卧室的结果，请参见图19），以更全面地分析语义属性。对于塔图像，Image2StyleGAN的插值结果显示出不满意的伪影。同时，一些由Image2StyleGAN进行的插值在语义上没有意义（例如，插值后的图像不再是塔了）。相反，我们的方法得到的反演代码导致了更令人满意的插值。一个值得注意的事情是，在插值两种不同类型的塔（例如，一个有一个尖顶，另一个有多个尖顶）时，使用我们的方法进行插值的图像仍然是高质量的塔。这证明了我们算法的领域内属性。表II提供了定量评估，显示我们的方法在很大程度上超越了Image2StyleGAN。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/70e987e6de3c44b5ba45161ec8e967d3.jpeg" width="70%" />

</div>

<div align=center>  
  <img src="https://img-blog.csdnimg.cn/direct/51a0782a482a4223a4c08e7fdc8e42f1.jpeg" width="70%" />

</div>

### 语义操作
图像操作是另一种检验嵌入的潜在代码是否与GANs学习到的语义知识对齐的方法。如先前工作[29]、[30]所指出的，GANs可以在潜在空间中学习到丰富的语义，通过线性变换潜在表示来进行图像操作。这可以被公式化为：

$$
x_ {edit} = G(z_ {inv} + \alpha n),
$$

其中 $n$ 是对应于潜在空间中特定语义的正常方向，$\alpha$ 是操作步骤。换句话说，如果潜在代码沿着这个方向移动，输出图像中包含的语义应该相应变化。我们遵循[29]来搜索语义方向 $n$。

图5显示了使用Images2StyleGAN [16]和我们的领域内GAN反演来操作人脸、塔和卧室的比较结果（对于教堂的结果，请参见图20）。我们可以看到，我们的方法显示出比Image2StyleGAN更令人满意的操作结果。以图5中的人脸操作为例，当使用Image2StyleGAN的代码添加微笑时，女演员的头发变得模糊，当编辑头发颜色时，身份变化很大。这是因为它只关注于重建每个像素的值，却忽略了反演代码中包含的语义信息。相反，我们的领域内反演在编辑特定面部属性时能够保留大多数其他细节。对于塔操作，我们从图5中观察到，我们的领域内方法通过减少和增加语义层面都超越了基于MSE的优化。例如，当在天空中添加云时，Image2StyleGAN会将塔和天空一起模糊，因为它只恢复了像素级别的图像，而没有考虑恢复对象的语义含义。因此，云被添加到整个图像上，不管特定区域是否属于天空或塔。相反，我们的算法在编辑云时几乎不影响塔本身，这表明我们的领域内反演可以为图像重建产生语义信息丰富的潜在代码。对于卧室操作，由Image2StyleGAN获得的结果在添加或删除特定语义时显示出伪影和模糊。我们在表II中也包括了操作任务的定量评估。我们可以告诉，我们的领域内反演在所有评估指标上都超越了Image2StyleGAN。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/d8994f9588c84c38a959982147c3e099.jpeg" width="70%" />

</div>

### 语义扩散
语义扩散的目标是将目标图像的特定部分（通常是最具代表性的部分）扩散到另一个图像的上下文中。我们希望融合的结果保留目标图像的特征（例如，面部的身份）的同时，适应上下文信息。具体来说，给定一对目标-上下文图像，我们首先从目标图像中裁剪出所需部分，然后将其粘贴到上下文图像上。然后，我们使用我们的领域引导编码器来推断缝合图像的潜在代码。由于我们编码器的领域对齐属性，代码的重建已经可以捕捉到目标补丁及其周围环境的语义，并进一步平滑内容。以这个代码作为初始化，我们最后通过仅使用目标前景区域来计算重建损失来进行掩蔽优化。通过这种方式，我们不仅能够将目标图像扩散到任何其他上下文中，而且还保持了上下文图像的原始风格。图6展示了一些示例，我们成功地将各种目标面部扩散到不同的上下文使用我们的领域内GAN反演方法。我们可以看到，结果很好地保留了目标面部的身份，并合理地融入了不同的环境。这与风格混合不同，因为我们结果图像的中心区域保持与目标图像相同。语义扩散操作的更详细分析可以在第VII节中找到。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/b5577e7ac83f44fe9c9592cb6d64a976.jpeg" width="70%" />

</div>

# V. 编码器分析

在我们提出的方法中，如图1(a)所示，我们在训练过程中同时更新编码器和鉴别器，同时保持生成器固定，其中鉴别器直接来自StyleGAN。因此，在本节中，我们分析了不同神经网络架构的编码器对GAN反演的质量和速度的影响。这项分析的结果使我们提出了一个直接的解决方案，使我们的方法能够在StyleGAN2上有效运行。

## A. 编码器架构
在第IV节中使用的编码器架构是一个包含卷积和池化层的14层CNN，最后是一个全连接层，产生最终的潜在代码。因此，我们感兴趣的是探索修改编码器架构是否能够提高GAN反演的结果。一个更深层次的网络架构提供了更高的网络容量，这可能潜在地提高了近似生成器反演的准确性。在我们对不同编码器架构的分析中，我们选择了ResNet变种（ResNet-18、ResNet-34和ResNet-50）和MobileNet作为主干。重要的是要注意，最浅的ResNet架构有18层，这比我们的简单编码器架构要深。此外，我们保持最后一个全连接层和训练损失函数在所有不同的编码器架构中保持不变。

如表III所示，对于人脸，随着网络深度的增加，MSE、SSIM和SWD有所改善，而FID波动。对于教堂，当网络深度增加时，MSE、SSIM和FID略有改善，而SWD波动。然而，值得注意的是，当深度增加时，反演时间迅速增长。关于反演速度，我们还尝试了MobileNet，结果也报告在表III中。从结果中我们可以观察到，反演速度并没有明显加快，但与我们的简单编码器架构相比，反演质量在某种程度上有所下降。这可能是因为MobileNet是为CPU设计的，而我们的测试是在GPU上进行的。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/91c1038bfde94557ba1ab06385eadef3.jpeg" width="70%" />

</div>


基于进行的实验，我们可以得出结论，增加编码器网络的深度通常会导致反演质量的提高，这由大多数性能指标表明。然而，这种改进是以牺牲反演速度为代价的，这突出了有效性和效率之间的权衡。尽管如此，我们的发现表明，对于StyleGAN反演任务，我们的简单编码器架构在有效性和效率之间取得了合理的平衡。使用不同架构重建的不同视觉结果包括在图8中，这也表明使用不同架构的重建输出之间的差异可以忽略不计。为了提高反演质量的其他解决方案的详细讨论，可以参考第VI节。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/c310dbbe9a7540b38da5498a6323b647.jpeg" width="70%" />

</div>

## B. 初始反演空间
在我们在StyleGAN2上实现我们的方法时，我们遇到了训练编码器时的不稳定性问题。例如，我们观察到训练没有收敛的情况，这表明损失没有减少，或者最终结果的质量很差，尽管训练损失有所下降。最初怀疑使用简单的编码器架构可能是这些问题的原因。然而，进一步尝试不同的编码器架构，如上所述，并没有得到更好的结果。因此，可能还有其他因素可能在训练期间导致不稳定。

回想我们在图1(a)中训练编码器的流程，它可以进一步详细说明，如图7所示，我们可以将这个流程分为两部分。第一部分是预训练的生成器，其中映射网络M将正态分布N映射到未知分布Wf，然后合成网络S将Wf映射到图像分布Xf。第二部分是编码器，它将真实图像分布Xr映射到潜在分布Wr，然后通过合成网络重塑以获得重建： $x_ {rec} = S(E(x_ {real}))$。当编码器训练完成时，我们希望编码器产生的分布Wr能够很好地与映射网络生成的分布Wf对齐，无论这两个分布在初始状态下有多远。同时，记住在编码器训练时，生成器是固定的，这意味着Wf是静止的。因此，训练编码器的过程的目标是最终使其输出Wr与Wf对齐。直观地说，当这两个分布在训练开始时很接近时，训练编码器是稳定的；否则，当它们相距甚远时，训练可能会变得不稳定，尤其是使用StyleGAN2时。为了解决这个问题，我们可以通过在Wr的初始分布上加上Wf的平均值来改善这两个分布的初始对齐。具体来说，编码器的输出首先加上Wf的平均值，然后送入合成网络：

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/44000eaee5f640dd9f4bde2c4a3e6ee2.jpeg" width="70%" />

</div>

$$
x_ {rec} = S(E(x_ {real}) + \bar{w}),
$$

其中 $\bar{w} = E_ {z \sim P} [M(z)]$ 是Wf的平均值。添加这样一个平均值有三个优点：首先，从优化的角度来看，向Wr添加 $\bar{w}$ 确保了这两个分布在一开始彼此接近，从而简化了优化过程并加快了收敛速度。其次，当添加 $\bar{w}$ 时，编码器只需要学习每个输入图像的残差信息，减少了学习难度。第三， $\bar{w}$ 可以被视为一个正则化器，它强制编码器的输出值更接近平均值 $\bar{w}$，促进了更多领域内潜在代码的生成。值得注意的是，在StyleGAN中合成图像时，给定的w通过使用线性插值 $w' = \bar{w} + \psi(w - \bar{w})$，其中 $\psi < 1$，通过 $\bar{w}$ 进行截断。这种截断技巧旨在通过某种程度降低生成图像的变化来提高平均图像质量。相反，我们流程中添加 $\bar{w}$ 的目的是简化编码器学习。

我们进行了比较研究，以评估在StyleGAN2上训练编码器时添加 $\bar{w}$ 的影响。如前所述，当不包含 $\bar{w}$ 时，编码器训练过程可能会失败（例如，发散的损失）。因此，我们选择了一个损失正常下降的情况，如图14(b)中所示的训练损失曲线。注意，两个损失曲线都以对数刻度绘制，因为不包含平均值时损失的大小明显大于包含平均值时的损失，这使得比较变得困难。没有 $\bar{w}$ 的训练损失始终比包含 $\bar{w}$ 的损失大得多，如图14(b)所示。此外，图9展示了两种情况下编码器重建结果的比较，即包含和不包含 $\bar{w}$，很明显，添加平均值时编码器重建质量显著提高。表IV进一步支持了添加平均值在提高编码器性能方面的有效性。在第VII节中，我们展示了在编码器训练期间包含和不包含平均潜在代码的初始重建的可视化结果。此外，我们与e4e[43]进行了比较，因为它也在StyleGAN2上进行了训练。如图9所示，e4e的结果与我们添加 $\bar{w}$ 的方法相比，保真度较低。表IV也证明了我们添加 $\bar{w}$ 的编码器在大多数指标上都能击败e4e，除了插值任务中的SWD。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/14bb0db339064f33b1dcfb40d67d5ded.jpeg" width="70%" />

</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/44df6d992b0b4aa48c3b5caf313ef958.jpeg" width="70%" />

</div>

<div align=center>  
  <img src="https://img-blog.csdnimg.cn/direct/7c64bb71633d4339b6d0a5b4bd5a4148.jpeg" width="70%" />

</div>


# VI. 重建质量和可编辑性之间的权衡

## A. 消融研究
如第III节所述，在编码器的初始训练之后，我们对每张图像执行领域正则化优化，以进一步提高重建质量。与之前的基于MSE的优化不同，我们引入了学习到的领域引导编码器作为正则化器，以将反演代码置于语义领域内，如公式(4)所述。这里，我们通过改变公式(4)中的权重 $\lambda_ {dom}$ 来研究编码器在优化过程中的作用。图10报告了在反演(MSE)和操作(FID)相应图像时， $\lambda_ {dom}$ 的定量结果，我们可以看到随着 $\lambda_ {dom}$ 的增加，重建MSE在增长，而操作图像的FID在下降。这表明了图像重建精度和编辑属性之间存在权衡。图11给出了 $\lambda_ {dom} = 0, 2, 10, 40$ 时的定性比较，我们也观察到了这种权衡。较大的 $\lambda_ {dom}$ 会使优化偏向于领域约束，使得反演代码在语义上更有意义（例如，语义将与编码器有更好的对齐）。相反，代价是目标图像不能在像素值上理想地恢复。在实践中，我们设置 $\lambda_ {dom} = 2$。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/3d1f08ef7a724bf99d5c13fb9d4373db.jpeg" width="70%" />

</div>
  
<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/87e41a199c324d5bae7824668f349b78.jpeg" width="70%" />

</div>

## B. 重新训练生成器
在本部分，我们探讨是否需要像[17]中所做的那样重新训练生成器。回想一下，StyleGAN生成器有两个部分。第一部分是映射网络，由八个全连接层组成，后面是Leaky ReLU，将潜在代码 $z$ 映射到中间潜在代码 $w$，由这些中间潜在代码形成的空间称为 $W$ 空间。在StyleGAN中， $z$ 和 $w$ 的维度都是512。生成器的另一部分称为合成网络，它以逐层的方式通过自适应实例归一化（AdaIN）操作符接收 $w$ 并生成合成图像。对于一个能够合成256×256图像的生成器，合成网络包含14个卷积层。这意味着由映射网络产生的单个潜在代码 $w$ 将被重复14次，然后送入每个卷积层。对于GAN反演任务，一些工作[16]，[17]引入了W+空间。也就是说，他们使用14个不同的 $w$ 来重建图像，而不是使用一个 $w$ 重复14次。这意味着反演代码的维度通过14倍（即， $W$ 空间的维度是512，W+的维度是14×512=7168）扩大于原始的，并且反演结果有了实质性的改进。这样做的一个缺点是生成器需要重新训练，这是耗时的。因此，在本节中，我们探索是否不需要重新训练生成器就可以使用W+来反演图像。

表V展示了使用StyleGAN和StyleGAN2在FFHQ数据集上进行重建和插值的定量结果，无论是否重新训练生成器。如所示，我们观察到当重新训练生成器时，重建有所改进，而插值质量恶化。相反，当不重新训练生成器时，插值质量提高，而重建质量下降。这是合理的，因为当重新训练生成器时，生成器的 $W$ 空间比不重新训练的生成器的 $W$ 空间大14倍，为编码器提供了更大的空间来探索，自然有利于提高重建质量。然而，更大的空间也意味着同一图像中的相同语义被分散到更大的空间中，导致这些语义在某种程度上难以很好地对齐，导致相对较差的插值结果。总之，这些结果为重建质量和编辑属性之间的权衡提供了进一步的证据。

我们注意到表V中StyleGAN2的重建结果比StyleGAN的好，但插值结果正好相反。我们怀疑这种差异是由于统计平均代码 $\bar{w}$。所有反演代码都建立在 $\bar{w}$ 之上，这限制了插值两个代码时的多样性，最终损害了FID指标。我们在其他数据集上进行了实验，如LSUN Tower和LSUN Bedroom，结果如表7所示，证实了表V中观察到的模式。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/7d772033d89548438a5ca66c92a9ab3e.jpeg" width="70%" />

</div>

## C. 扩展反演空间
如第VI-B节所见，潜在空间的维度可以影响重建结果。那么还有其他方法可以引入更多维度来进一步提高重建精度吗？答案是肯定的！以前的工作[3]，[48]，[73]在反演图像时探索了生成器特征图中的噪声。因此，在本部分，我们尝试将这些噪声融入我们提出的编码器中。具体来说，基于StyleGAN的生成器在特征图中注入随机噪声，以提高合成图像的质量和随机变化。这些随机变化包括使用相同的潜在代码但重新采样特征图中的噪声时，头发、轮廓和背景的变化。在将这些生成器作为固定解码器用于编码器训练过程时，必须固定随机噪声，因为每个输入对应一个输出。因此，我们希望在重建输入图像时能够利用这些噪声，而不是固定它们。也就是说，生成器中的随机噪声将被编码器提取的特征所取代，如图12所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/f066401db7304945ade19e9fb5bc81b7.jpeg" width="70%" />

</div>

在这种情况下，编码器被设计成与生成器对称，以匹配噪声的数量和分辨率。以256×256图像为例。生成器有十四层，包括七个块（即，从分辨率4×4到256×256，每个块有两层卷积层）。为简化表示，我们用B-1到B-7表示块1到7。我们逐步替换生成器中的噪声，以观察它们对重建结果的影响。具体来说，我们首先用编码器在分辨率4×4处提取的特征替换B-1中的噪声，而其余块仍然使用固定噪声。然后，我们通过替换生成器中的噪声并添加B-2，使用编码器在分辨率8×8处提取的特征。最后，B-7意味着用编码器提取的特征替换生成器中的所有噪声。

在图14(a)中，我们展示了在FFHQ数据集上替换每个块中相应的噪声时的训练损失，其中我们看到随着越来越多噪声被替换，训练损失变得越来越低。值得注意的是，当替换所有噪声时，训练损失在一开始就变得最小，仅在8个RTX 2080 Ti GPU上需要半小时。表VI显示了定量结果，我们报告了在重建时涉及不同块的MSE和SSIM，以及在插值时的FID和SWD。我们从表VI中观察到，当替换生成器中的所有噪声时，重建MSE下降了一百多倍，SSIM也提高了近一倍。然而，随着更多噪声的涉及，编辑任务（如插值）的性能变差，进一步证明了权衡的存在。图13也展示了一些重建结果，以及编码器在B-7的第一个卷积层处提取的特征，这表明非常复杂的图像可以被恢复，包括它们的背景和许多其他细节。这是合理的，因为当替换生成器中的所有噪声时，编码器将使用181,920个参数来重建一个大小为256×256，总共有196,608个像素的图像。一个可能的方向是图像处理，因为它的U-Net-like架构可以精确地重建输入，但与原始的U-Net相比网络容量较低。然而，我们不进一步讨论这一点，因为我们的论文重点是图像编辑。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/cdb9635a72754a5dbb98f4cb40326ff0.jpeg" width="70%" />

</div>

<div align=center>  
  <img src="https://img-blog.csdnimg.cn/direct/3d9ada02434642b199a05c72bd28f178.jpeg" width="70%" />
</div>

总之，随着反演精度的提高，编辑质量趋于下降。这是正常的，因为生成器不能从潜在空间中合成一个与真实图像完全匹配的图像。因此，随着真实图像重建精度的提高，一些额外的信息需要被借用或激活，例如我们案例中的噪声，这在合成图像时起到辅助作用，但在完美重建真实图像时起到关键作用。因此，在重用GANs对真实图像学到的知识时，出现了明显恶化。因此，重建精度和编辑质量之间必须存在权衡。

# VII. 讨论和结论

在本项工作中，我们探索了GAN反演任务中反演代码的语义属性，并提出了一种新颖的领域内反演方法。据我们所知，这是第一次尝试显式地反演一个预训练的GAN模型，同时考虑潜在空间中编码的语义知识。我们展示了仅仅恢复目标图像像素值的代码并不足以在语义层面上代表图像。例如，在图15中，我们使用面部合成模型反演了不同类型的图像实例（即，面部、猫面部和卧室）。最后一列显示了Image2StyleGAN的结果，它恢复了猫或卧室，使用了学习合成人类面部的领域知识。相比之下，使用我们的领域内反演的重建中仍然可以观察到面部轮廓（第三列）。这从不同角度证明了我们方法在产生语义有意义的代码方面的优越性。以反演卧室（第三行）为例。卧室图像是训练数据的领域之外，GAN模型不应该能够学习到与卧室相关的语义。
因此，重用面部知识来表示卧室是定义不清的。尽管我们总是可以使用更多的参数来过度拟合卧室的像素值（例如，最后一列），但这种过度拟合将无法支持语义图像操作。从这个角度来看，我们的领域内反演将反演代码置于原始领域内，使其在语义上有意义。换句话说，我们的目标是找到一个合适的代码，从像素层面和语义层面恢复目标图像。这种领域内反演显著地促进了真实图像编辑。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/6b6ceabe12974ff5a8a8f75beb6d5174.jpeg" width="70%" />
</div>

# 声名
本文内容为论文学习收获分享，受限于知识能力，本文对原文的理解可能存在偏差，最终内容以原论文为准备。  
本文信息旨在传播和交流学术，其内容由作者负责，不代表本号观点。文中内容如涉及作品文字。图片等内容、版权和其他问题，请及时与我们联系，我们将在第一时间删文处理。
