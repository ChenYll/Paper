# 题目：[Ultra Fast Deep Lane Detection With Hybrid Anchor Driven Ordinal Classification ](https://ieeexplore.ieee.org/document/9795098/)
## 超快速深度车道检测与混合锚驱动序数分类
Zequn Qin, Pengyi Zhang, 和 Xi Li

**源码链接：** https://github.com/cfzd/Ultra-Fast-Lane-Detection-v2

## 摘要
现代方法主要将车道检测视为像素级分割问题，这在解决效率和具有挑战性场景（如严重遮挡和极端光照条件）的问题上存在困难。受人类感知的启发，我们在严重遮挡和极端光照条件下识别车道主要依赖于上下文和全局信息。基于这一观察，我们提出了一种新颖、简单但有效的公式，旨在实现超快速度和解决具有挑战性场景的问题。具体来说，我们将车道检测过程视为一个使用全局特征的锚驱动序数分类问题。首先，我们使用一系列混合（行和列）锚上的稀疏坐标来表示车道。借助锚驱动的表示，我们随后将车道检测任务重新构建为序数分类问题以获取车道的坐标。我们的方法可以显著降低计算成本，并使用序数分类公式的大感受野属性，我们也能够处理具有挑战性的场景。在四个车道检测数据集上的广泛实验表明，我们的方法在速度和准确性方面都能达到最先进的性能。一个轻量级版本甚至能够达到每秒300帧以上（FPS）。

## 引言
车道检测是自动驾驶和高级驾驶辅助系统（ADAS）[1]的一个基本组成部分，它区分并定位道路上的车道标记。尽管深度学习模型取得了巨大成功，但仍有一些重要且具有挑战性的问题需要解决。

第一个问题是效率问题。在实践中，车道检测算法被频繁执行，以提供即时的感知结果和受限的车辆计算设备用于下游任务，这要求快速检测速度。此外，以前的车道检测方法[2]、[3]、[4]、[5]主要基于分割，这被制定为一个密集的自底向上学习流水线，使其难以实现快速速度。

除了效率问题，另一个挑战是“无视觉线索”问题，如图1所示。车道检测任务[2]、[6]是要找到车道的位置，无论车道是否可见。这样，如何处理严重遮挡和极端光照条件下没有可见信息的场景是车道检测任务的一个主要难点。为了缓解这个问题，潜在的额外线索是关键。例如，道路形状、汽车前进方向趋势、未被遮挡的车道端点等，都可能有益于检测。为了使使用这些额外线索成为可能，扩大感受野以利用更多信息是车道检测的首选。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/5e072923042144d98553d165144631c2.jpeg" width="70%" />
</div>


这引发了一个自然的问题：我们能否找到一个快速且全局的公式，具有大感受野来处理车道检测任务？基于上述动机，我们提出了一个稀疏的自顶向下公式来解决效率和无视觉线索问题。首先，我们提出了一种新颖的行锚驱动表示法用于车道。一条车道可以通过一系列预定义的行锚上的坐标来表示，如图3所示。由于一条车道可以通过一组关键点（在固定的稀疏行锚系统中）很好地表示，因此可以通过锚驱动表示的稀疏性来解决效率问题。其次，我们提出使用基于分类的方式来学习锚驱动表示下的车道坐标。使用基于分类的方式（处理整个全局特征），感受野与整个输入一样大。它使网络能够更好地捕获车道检测的全局和长距离信息，无视觉线索问题也可以有效缓解。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/befb3f6911c248ce81fc2edd112b9115.jpeg" width="70%" />
</div>

此外，我们在这项工作中将车道表示从行锚扩展到混合锚系统。我们的观察结果是行锚系统可能不适用于所有类型的车道，并且可能导致放大的定位问题。如图2a和2b所示，当使用行锚时，侧车道的定位精度显著低于自我车道。如果我们使用列锚会怎么样？在图2c中，我们可以看到相反的现象，即列锚系统对自我车道的定位能力较差。我们将这种现象命名为放大定位误差问题。这个问题使得行锚难以定位水平（侧车道）车道，同样也使得列锚难以定位垂直车道（自我车道）。基于上述观察，我们提出使用混合（行和列）锚来分别表示不同的车道。具体来说，我们为自我车道使用行锚，为侧车道使用列锚。这样，放大定位误差问题可以得到缓解，性能也可以得到提高。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/df52de806a084b34b08f92090b0c8faf.jpeg" width="70%" />
</div>

有了混合锚系统，车道可以通过锚系统上的坐标来表示。如何有效地学习这些坐标是另一个重要问题。最直接的方法是使用回归。通常，回归方法适用于局部范围预测设置[7]、[8]、[9]、[10]、[11]、[12]、[13]、[14]，并且在建模长距离和全局定位[15]、[16]、[17]方面相对较弱。为了应对全局范围预测，我们提出以基于分类的方式学习车道的坐标，这使用不同类别表示不同的坐标。在这项工作中，我们进一步将原始分类扩展到序数分类。在序数分类中，相邻类别具有接近和序数关系，这与原始分类不同。例如，在ImageNet[18]分类任务中，第7类是鳐鱼（一种鱼），而第8类是公鸡。在我们的工作中，类别是有序的（例如，第8类的车道坐标总是空间上位于第7类的右侧）。序数分类的另一个属性是类别空间是连续的。例如，非整数值的类别如7.5类是有意义的，并且可以被视为第7类和第8类之间的中间类别。为了实现序数分类，我们提出了两个损失函数一起建模类别之间的序数关系，包括一个基本分类损失和一个数学期望损失。利用序数关系和连续类别空间属性，我们可以使用数学期望而不是argmax来获得预测的连续类别。通过同时约束基本和期望损失，输出可以具有更好的序数关系并有利于车道定位。

总之，我们工作的主要贡献是三方面的。1) 我们提出了一种新颖、简单但有效的车道检测公式。与以前的方法相比，我们的方法将车道表示为基于锚点的坐标，并且坐标是以基于分类的方式学习的。这种公式在解决无视觉线索问题时超快且有效。2) 基于提出的公式，我们提出了一个混合锚系统，它进一步扩展了以前的行锚系统，并且可以有效减少定位误差。此外，基于分类的学习进一步扩展到序数分类问题，利用了基于分类定位中的自然序数关系。3) 提出的方法在速度和性能方面都达到了最先进的水平。我们最快的模型可以达到每秒300帧以上（FPS）的性能。

本文是我们之前会议出版物[20]的扩展。与会议版本相比，本文的扩展如下：
- 混合锚系统 通过观察放大误差问题，我们提出了一种新的混合锚系统，与之前的出版物相比，可以有效地减少定位误差。
- 序数分类损失 我们提出了新的损失函数，将车道定位视为序数分类问题，这进一步提高了性能。
- 表述与实验 大部分论文都进行了重写，以提供更清晰的表述和说明。我们还提供了更多的分析、可视化和结果，以更好地涵盖我们工作的范围。在这个版本中，我们还提供了在相同速度下性能提高了6.3点的更强结果。

# 3 超快速车道检测
在本节中，我们将详细描述我们的方法。首先，我们将展示在提出的混合锚系统上车道的坐标表示。其次，我们将展示深度网络架构的设计和相应的序数分类损失。最后，将详细阐述复杂度分析。

## 3.1 使用锚点的车道表示
为了表示车道，我们引入了用于车道检测的行锚点，如图3所示。车道通过行锚点上的点来表示。然而，行锚点系统可能会导致放大的定位误差问题，如图2所示。因此，我们进一步将行锚点系统扩展到混合锚点系统。
这个问题的原因在于图5所示。假设没有任何锚点系统时理想的最小定位误差是“ $\epsilon$ ”，这可能是由网络偏差、注释错误等引起的。我们可以看到，在行锚点系统中，误差带宽乘以一个因子  $\frac{1}{\sin(\theta)}$ 。当车道和锚点之间的角度  $\theta$  很小时，放大因子  $\frac{1}{\sin(\theta)}$  会趋向于无穷大。例如，当一条车道严格水平时，用行锚点系统表示车道是不可能的。这个问题使得行锚点很难定位更水平的车道（通常是侧车道），同样，它也使得列锚点难以定位更垂直的车道（通常是自我车道）。相反，当车道和锚点垂直时，由锚点系统引入的误差是最小的（在这种情况下  $\theta = 0$ ），它等于理想的定位误差“ $\epsilon$ ”。
受上述观察的启发，我们进一步提出使用混合锚点来表示车道。对于不同类型的车道，我们使用不同的锚点系统来减少放大的定位误差。具体来说，规则是：一条车道只能分配给一种类型的锚点，并且选择对车道更垂直的锚点类型。在实践中，车道检测数据集如CULane [2]和TuSimple [53]只注释了两条自我车道和两条侧车道，如图2a所示。因此，我们为自我车道使用行锚点，为侧车道使用列锚点，混合锚点系统可以缓解放大的定位误差问题。
有了混合锚点系统，我们可以将车道表示为锚点上的一系列坐标，如图4所示。设  $N_{row}$  为行锚点的数量， $N_{col}$  为列锚点的数量。对于每条车道，我们首先分配相应的锚点系统，该系统具有最小的定位误差。然后我们计算车道和每个锚点之间的线-线交点，并记录交点的坐标。如果车道在某些锚点之间没有交点，坐标将被设置为-1。假设分配给行锚点的车道数量为  $N_{r\_lane}$ ，分配给列锚点的车道数量为  $N_{c\_lane}$ 。车道在图像中可以由一个固定大小的目标  $T$  表示，其中每个元素是车道的坐标或-1，其长度为  $N_{row} \cdot N_{r\_lane} + N_{col} \cdot N_{c\_lane}$ 。 $T$  可以分成两部分  $T_r$  和  $T_c$ ，分别对应于行锚点和列锚点的部分，大小分别为  $N_{row} \cdot N_{r\_lane}$  和  $N_{col} \cdot N_{c\_lane}$ 。记号可以在表1中看到。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/a32d10ba7e404aa6bdc225a477a449c8.jpeg" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/157f31e21d7b4761b197f5521becf578.jpeg" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/98d4d64fc2fb4d74b38dd28a7160d7fe.jpeg" width="70%" />
</div>

## 3.2 锚点驱动的网络设计
有了车道表示与混合锚点的帮助，我们设计网络的目标是使用分类学习固定大小的目标  $T_r$  和  $T_c$ 。为了使用分类学习  $T_r$  和  $T_c$ ，我们将  $T_r$  和  $T_c$  中的不同坐标映射到不同的类别。假设  $T_r$  和  $T_c$  被归一化（ $T_r$  和  $T_c$  的元素范围从0到1或等于-1，即“无车道”的情况），并且类别的数量是  $N_{r\_dim}$  和  $N_{c\_dim}$ 。

映射可以写成：

$$
\begin{align*}
    T_{r\_cls}(i,j) &= \left\lfloor \frac{T_r(i,j)}{N_{r\_dim}} \right\rfloor, \\
    T_{c\_cls}(m,n) &= \left\lfloor \frac{T_c(m,n)}{N_{c\_dim}} \right\rfloor,
\end{align*}
$$

其中  $T_{r\_cls}$  和  $T_{c\_cls}$  是坐标映射的类别标签， $\lfloor \cdot \rfloor$  是向下取整操作， $T_{r\_cls}(i,j)$  是  $T_{r\_cls}$  中第  $i$  行第  $j$  列的元素。这样，我们可以将学习混合锚点上的坐标转换为两个分类问题，维度分别为  $N_{r\_dim}$  和  $N_{c\_dim}$ 。

对于无车道的情况，即  $T_r(i,j)$  或  $T_c(m,n)$  等于 -1，我们使用一个额外的双路分类来指示  $T_{r\_next}$ ：

$$
\begin{align*}
    T_{r\_next}(i,j) &= 
    \begin{cases} 
      1, & \text{if } T_r(i,j) \neq -1 \\
      0, & \text{otherwise}
    \end{cases}
    \quad \text{for } i \in \{1, ..., N_{row}\}, j \in \{1, ..., N_{r\_lane}\}, \\
    T_{c\_next}(m,n) &= 
    \begin{cases} 
      1, & \text{if } T_c(m,n) \neq -1 \\
      0, & \text{otherwise}
    \end{cases}
    \quad \text{for } m \in \{1, ..., N_{col}\}, n \in \{1, ..., N_{c\_lane}\}.
\end{align*}
$$

通过上述推导，整个网络需要学习  $T_{r\_cls}$ ， $T_{c\_cls}$ ， $T_{r\_next}$  和  $T_{c\_next}$  通过两个分支，它们是定位分支和存在分支。假设输入图像的深度特征是  $X$ ，网络可以写成：

$$
P, E = f(\text{flatten}(X)),
$$

其中  $P$  和  $E$  是定位和存在分支， $f$  是分类器， $\text{flatten}(\cdot)$  是展平操作。 $P$  和  $E$  的输出都由两部分组成  $P_r$ ， $P_c$ ， $E_r$  和  $E_c$ ，分别对应于行锚点和列锚点。 $P_r$  和  $P_c$  的大小分别是  $N_{r\_lane} \cdot N_{row} \cdot N_{r\_dim}$  和  $N_{c\_lane} \cdot N_{col} \cdot N_{c\_dim}$ ，其中  $N_{r\_dim}$  和  $N_{c\_dim}$  是行锚点和列锚点的映射分类维度。 $E_r$  和  $E_c$  的大小分别是  $N_{r\_lane} \cdot N_{row} \cdot 2$  和  $N_{c\_lane} \cdot N_{col} \cdot 2$ 。

在方程(4)中，我们直接将深度特征从骨架展平并输入到分类器中。与之相比，传统的分类网络使用全局平均池化（GAP）。我们使用展平而不是GAP的原因是，我们发现空间信息对于基于分类的车道检测网络至关重要。使用GAP将消除空间信息，导致性能下降。


## 3.3 序数分类损失

正如我们在方程(1)中所看到的，一个基本属性是上述分类网络中的类别具有序数关系。在我们的分类网络中，相邻类别被定义为具有接近和序数关系，这与常规分类不同。为了更好地利用序数关系的先验，我们提出使用一个基本分类损失和一个期望损失。

基本分类损失定义为：

$$
L_{cls} = \sum_{i=1}^{N_{r\_lane}} \sum_{j=1}^{N_{row}} L_{CE}(P_{r}(i,j), \text{onehot}(T_{r\_cls}(i,j))) + \sum_{m=1}^{N_{c\_lane}} \sum_{n=1}^{N_{col}} L_{CE}(P_{c}(m,n), \text{onehot}(T_{c\_cls}(m,n))),
$$

其中  $L_{CE}(\cdot)$  是交叉熵损失， $P_{r}(i,j)$  是分配给行锚点和第  $j$  行锚点的第  $i$  条车道的预测， $T_{r\_cls}(i,j)$  是  $P_{r}(i,j)$  对应的分类标签， $P_{c}(m,n)$  是分配给列锚点和第  $n$  列锚点的第  $m$  条车道的预测， $T_{c\_cls}(m,n)$  是  $P_{c}(m,n)$  对应的分类标签， $\text{onehot}(\cdot)$  是独热编码函数。

由于类别是序数的，预测的期望可以被视为平均投票结果。为了方便，我们称期望为：

$$
\begin{align*}
    \text{Exp}_ r(i,j) &= \sum_{k=1}^{N_{r\_dim}} \text{Prob}_ r(i,j,k) \cdot k, \\
    \text{Exp}_ c(m,n) &= \sum_{l=1}^{N_{c\_dim}} \text{Prob}_c(m,n,l) \cdot l,
\end{align*}
$$

其中  $\text{Prob}_ r(i,j,k)$  和  $\text{Prob}_ c(m,n,l)$  分别是  $P_{r}(i,j)$  和  $P_{c}(m,n)$  的 softmax 输出：

$$
\text{Prob}_ r(i,j) = \text{softmax}(P_{r}(i,j)), \quad \text{Prob}_ c(m,n) = \text{softmax}(P_{c}(m,n)).
$$

这样，我们可以约束预测的期望接近真实值。因此，我们有以下期望损失：

$$
L_{exp} = \sum_{i=1}^{N_{r\_lane}} \sum_{j=1}^{N_{row}} L_1(\text{Exp}_ r(i,j), T_{r\_cls}(i,j)) + \sum_{m=1}^{N_{c\_lane}} \sum_{n=1}^{N_{col}} L_1(\text{Exp}_ c(m,n), T_{c\_cls}(m,n)),
$$

其中  $L_1(\cdot)$  是平滑L1损失。期望损失的示意图如图7所示。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/50fdb99790b74915a392cde4bf65752f.jpeg" width="70%" />
</div>

我们可以看到，期望损失可以将预测分布的数学期望推向真实值的位置，从而有利于车道的定位。

此外，存在分支的损失  $L_{ext}$  定义为：

$$
L_{ext} = \sum_{i=1}^{N_{r\_lane}} \sum_{j=1}^{N_{row}} L_{CE}(E_{r}(i,j), \text{onehot}(T_{r\_next}(i,j))) + \sum_{m=1}^{N_{c\_lane}} \sum_{n=1}^{N_{col}} L_{CE}(E_{c}(m,n), \text{onehot}(T_{c\_next}(m,n))).
$$

最后，总损失可以写成：

$$
L = L_{cls} + \alpha L_{exp} + \beta L_{ext},
$$

其中  $\alpha$  和  $\beta$  是损失系数。

## 3.4 网络推理

在本节中，我们将展示在推理过程中如何获得检测结果。以行锚系统为例，假设  $P_{r}(i,j)$  和  $E_{r}(i,j)$  是第  $i$  条车道和第  $j$  个锚点的预测。那么  $P_{r}(i,j)$  和  $E_{r}(i,j)$  的长度分别是  $N_{r\_dim}$  和 2。车道每个位置的概率可以写成：

$$
\text{Prob}_r(i,j) = \text{softmax}(P _{r}(i,j)),
$$

其中  $\text{Prob}_ r(i,j)$  的长度是  $N_{r\_dim}$ 。然后，车道的位置是通过预测分布的数学期望获得的。此外，根据存在分支的预测，将过滤掉缺失车道的预测：

$$
\text{Loc}_ r(i,j) =
\begin{cases} 
    \sum_{k=1}^{N_{r\_dim}} \text{Prob}_ r(i,j,k) \cdot k, & \text{if } E_{r}(i,j,2) > E_{r}(i,j,1) \\
    -1, & \text{otherwise}
\end{cases},
$$

最后，获得的位置  $\text{Loc}$  将被缩放到适应输入图像的大小。网络架构的总体示意图如图6所示。


<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/974b0f6b44824d868791931905389b8f.jpeg" width="70%" />
</div>

## 3.5 分析与讨论

在本节中，我们首先分析我们方法的复杂度，并给出我们方法能够实现超快速度的原因。

为了分析复杂度，我们使用分割作为基线。我们公式（以行锚为例）和分割之间的差异如图8所示。可以看出，我们的公式比常用的分割方法简单得多。假设图像大小为  $H \times W$ 。由于分割是逐像素分类，它需要进行  $H \times W$  次分类。对于我们的方法，学习目标  $T$  的长度，它包含车道在混合锚上的坐标，是  $N_{row} \times N_{r\_lane} + N_{col} \times N_{c\_lane}$ 。由于我们只需要少量的锚点来表示车道，我们有  $N_{row} \approx H$  和  $N_{col} \approx W$ 。此外， $N_{r\_lane}$  和  $N_{c\_lane}$  是分配给行锚和列锚的车道数量，与其他变量相比非常小。因此，我们有：

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/b762802ba4e14d69a22f65bea99a5fa3.jpeg" width="70%" />
</div>

$$
N_{row} \times N_{r\_lane} + N_{col} \times N_{c\_lane} \ll H \times W,
$$

其中 #CLS 表示“分类的数量”。以 CULane [2] 数据集上的设置为例，我们有  $H = 320$ ， $W = 1600$ ， $N_{row} = 18$ ， $N_{col} = 41$ ，且  $N_{r\_lane} = N_{c\_lane} = 2$ 。我们方法的分类数量是 118，而分割的是  $5.12 \times 10^5$ 。考虑到分类维度，我们方法的理想计算次数是  $1.54 \times 10^4$ ，而分割的是  $2.56 \times 10^6$ 。我们分类头部和分割头部在 ERFNet [36], [58] 上的计算成本分别是 0.04 GMac 和 30.86 GMac。

除了理论分析，我们方法的实际前向传递时间如图9a所示。我们可以看到，骨架占据了大部分时间。相比之下，所提出的基于分类的车道检测头部非常高效，只占用了整个推理时间的不到5%。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/56ce51b2f17046d2bd1a76da7d1c30db.jpeg" width="70%" />
</div>

## 4.1 实验设置

在本节中，我们将展示我们方法的有效性，通过广泛的实验。以下部分主要关注三个方面：1) 实验设置。2) 我们方法的消融研究。3) 在四个主要车道检测数据集上的结果。

### 4.1.1 数据集

为了评估我们的方法，我们在四个广泛使用的基准数据集上进行了实验：TuSimple [53]、CULane [2]、CurveLanes [6] 和 LLAMAS [59] 数据集。TuSimple 数据集是在高速公路上稳定光照条件下收集的。相反，CULane 数据集包含九种不同场景，包括正常、拥挤、曲线、耀眼光、夜晚、无线、阴影和箭头在城市区域。CurveLanes 数据集专注于更多曲线场景，LLAMAS 数据集是使用地图收集的。数据集的详细信息可以在表2中看到。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/aa6ea05705654001a1f6920e69e29421.jpeg" width="70%" />
</div>

### 4.1.2 评估指标

数据集的官方评估指标是不同的。对于 TuSimple 数据集，评估指标是准确度。准确度是通过以下公式计算的：

$$
\text{accuracy} = \frac{C_{\text{clip}}}{P_{\text{clip}} + S_{\text{clip}}},
$$

其中  $C_{\text{clip}}$  是正确预测的车道点的数量， $S_{\text{clip}}$  是每个剪辑中地面真实值的总数。除了准确度，我们还对所有数据集使用 CULane 的评估指标，其中交并比（IoU）是在地面真实值和预测之间计算的。IoU 大于 0.5 的预测被认为是真正的正面。F1-分数被作为评估指标，并定义如下：

$$
F1 = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}},
$$

其中 Precision  $= \frac{TP}{TP + FP}$ ，Recall  $= \frac{TP}{TP + FN}$ ，FP 和 FN 分别是误报和漏报。

### 4.1.3 实现细节

超参数设置显示在表3中。锚点数量和分类维度的数量的消融研究可以在第4.2.4节和第4.2.5节中看到。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/f1ff96d2ae2f4bafb8227b1296f0e6f6.jpeg" width="70%" />
</div>

在优化过程中，图像被调整大小为在 CULane 上为  $1600 \times 320$  和在 TuSimple 上为  $800 \times 320$ 。方程(10)中的损失系数  $a$  和  $b$  分别设置为0.05和1。批量大小设置为每个GPU 16，所有数据集的总训练周期设置为30。学习率设置为0.1，使用SGD优化器，在第25个周期时减少10倍。所有模型都是使用 PyTorch [60] 和 Nvidia RTX 3090 GPU进行训练和测试的。

### 4.1.4 特征级测试时间增强（FLTTA）

在这部分，我们展示了我们方法的测试时间增强方法。因为我们的方法是基于全局特征的分类方式工作，这为我们在特征级别上进行快速测试时间增强提供了机会。与目标检测中的测试时间增强（TTA）不同，后者通常需要在TTA期间重复计算整个骨架，我们在骨架特征上直接进行FLTTA。计算一次骨架特征，然后在上下左右方向上进行空间位移复制。然后将五个增强的特征副本批量输入分类器。最后，输出结果在测试期间集成以提供更好的预测。由于骨架特征只计算一次，并且分类器的计算采用批量方式，利用GPU的并行机制，FLTTA几乎和没有TTA的普通测试一样快。FLTTA的前向传递时间饼图如图9b所示。

### 4.1.5 数据增强

通过简单的数据增强，如调整大小和裁剪，所提出的方法可以迅速过度拟合整个训练集（接近100%的训练准确度，而在测试集上性能差）。为了克服过度拟合问题，我们提出了一种空间位移数据增强，它随机移动整个图像和车道注释，使网络学习车道的空间模式。由于图像和车道注释的一些部分在空间位移后被裁剪，我们扩展车道注释直到图像边界。图10显示了增强。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/9c81b3db62ab4345b664433454d39582.jpeg" width="70%" />
</div>

## 4.2 消融研究

在本节中，我们通过几个消融研究来验证我们的方法。所有消融研究的实验设置与第4.1节相同。所有消融研究的实验都是使用ResNet-18网络作为我们的骨架模型。

### 4.2.1 混合锚系统的有效性

正如我们在第3.1节中所述，行锚和列锚系统对车道检测扮演着不同的角色。基于此，我们提出了一个混合锚系统，它为相应的锚点类型分配不同的车道。

为了验证混合锚系统的有效性，我们在CULane上进行了三个实验。结果显示在表4中。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/5c78b9128d354629ad4acce2e0d393f7.jpeg" width="70%" />
</div>


我们可以看到，与仅使用行锚和列锚相比，混合锚系统带来了显著的改进，展示了混合锚系统的有效性。

### 4.2.2 序数分类的有效性

我们的方法将车道检测表述为一个序数分类问题。一个自然的问题是，其他方法如回归和常规分类如何。

对于回归方法，我们将我们流程中的分类器头部替换为一个类似的回归头部。训练损失被替换为平滑L1损失。对于常规分类方法，我们使用与我们流程中相同的分类器头部。分类和序数分类之间的差异在于损失和后处理。1) 分类设置仅使用交叉熵损失，而序数分类设置使用方程(10)中的所有三种损失。2) 分类设置使用argmax作为其标准后处理，而序数分类设置使用期望。比较结果显示在表5中。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/08e9c80f33404e1bb0aa55d42b92b74a.jpeg" width="70%" />
</div>

我们可以看到，带有期望的分类可以获得比标准分类方法更好的性能。同时，基于分类的方法一致优于基于回归的方法。

### 4.2.3 序数分类损失的消融

如第3.3节所述，我们将车道检测问题建模为序数分类问题。为了验证所提模块的有效性，我们展示了序数分类损失的消融研究。

如表6所示，我们提出的期望损失约束有效地改进了车道检测的性能。所提出的期望损失与标准交叉熵损失具有不同的几何属性，期望损失像是通过减少远离真实值的logits的值并增加接近真实值的logits的值，逐渐将预测的期望推向真实值。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/87e016df57dd4eb3980df1b8bf3ee14e.jpeg" width="70%" />
</div>

### 4.2.4 分类维度的影响

如方程(4)所述，我们使用基于分类的公式来检测车道，并且不同的车道位置用不同的类别来表示。这引发了一个问题，进行车道检测需要多少个类别。为了讨论这个问题，我们首先将行锚的分类维度  $N_{r\_dim}$  设置为200，并以列锚的分类维度  $N_{c\_dim}$  为25、50、100和200进行实验。结果显示在图11a中。然后，我们将  $N_{c\_dim}$  固定为100，并以  $N_{r\_dim}$  为50、100、200和400进行实验。结果显示在图11b中。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/9ae99266742d434f9c602a71f3593949.jpeg" width="70%" />
</div>

我们可以看到，随着分类维度的增加，性能首先增加然后减少。较小的维度下，分类本质上更容易，但每个类别代表的位置范围更广，即每个类别的定位能力更差。较大的维度下，每个类别代表的位置范围更窄（每个类别的定位能力更好），但分类本身的难度更大。最终性能是在分类难度和每个类别的定位能力之间的权衡。因此，我们将  $N_{c\_dim}$  设置为100，将  $N_{r\_dim}$  设置为200。

### 4.2.5 锚点数量的影响

我们方法中另一个重要的超参数是用于表示车道的锚点数量（ $N_{row}$  和  $N_{col}$ ）。在本实验中，我们将行锚的数量  $N_{row}$  设置为18（遵循[2]），并以列锚的数量  $N_{col}$  为10、20、40、80和160进行实验。结果显示在图12a中。然后，我们将  $N_{col}$  设置为40，并以  $N_{row}$  为5、9、18、36和72进行实验。结果显示在图12b中。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/a6c8de6c90904d49a6df2739411e4865.jpeg" width="70%" />
</div>

我们可以看到，随着行锚数量的增加，性能通常也会增加。但是检测速度也逐渐下降。因此，我们为基于ResNet-18的模型将  $N_{row}$  和  $N_{col}$  分别设置为18和40，以在性能和速度之间取得平衡。对于较大的模型，如ResNet-34，我们将  $N_{row}$  和  $N_{col}$  分别设置为72和80。

## 4.3 结果

本节展示了在四个车道检测数据集上的结果，这些数据集是TuSimple、CULane、CurveLanes和LLAMAS。在这些实验中，使用ResNet-18和ResNet-34作为我们的骨架模型。

对于CULane数据集，我们比较了包括SCNN [2]、SAD [3]、ERFNet [36]、SIM-CycleGAN [61]、CurveLanes [6]、SGNet [47]、RESA [35]、LaneATT [46]和FOLOLane [38]在内的七种方法。比较了F1分数和运行时间。结果可以在表7中看到。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/c9abc4215a5b4e33971160ba0d39b33f.jpeg" width="70%" />
</div>

从表7可以观察到，我们的方法实现了最快的速度。与之前的会议版本相比，我们可以获得在相同速度下性能提高了6.3点的更强结果。这证明了我们提出的方法在这些具有挑战性的场景中的有效性，因为我们的方法能够利用全局信息来解决无视觉线索和效率问题。最快的模型可以达到每秒300帧以上（FPS）。

对于TuSimple车道检测基准，我们比较了包括Res18-Seg [62]、Res34Seg [62]、LaneNet [5]、EL-GAN [63]、SCNN [2]、SAD [3]、SGNet [47]、LaneATT [46]和LSTR [44]在内的十种方法。在这个实验中，比较了F1分数、准确度、误报（FP）、漏报（FN）和运行时间。我们的方法的运行时间是记录100次运行的平均时间。为了验证我们的方法，我们使用了两种协议。协议1输出所有车道，缺失的车道用充满无效值的车道表示，这与会议版本相同。协议2直接丢弃缺失的车道。结果可以在表8中看到。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/b192bce658ab4bafa33738a872cda1eb.jpeg" width="70%" />
</div>

从表8可以看出，我们的方法在保持极快运行速度的同时，实现了与最先进方法相当的性能。我们方法与SCNN相比，运行时间快了41.7倍。

另一个值得注意的有趣现象是，当我们的方法使用与普通分割相同的骨架网络时，即带有resnet骨架的DeeplabV2 [62]模型，我们的方法在性能上也获得了更好的结果，并且速度更快。这个结果表明，我们的方法比分割公式更好，并验证了我们公式的有效性。

对于CurveLanes数据集，我们在表9中展示了结果。可以看出，我们的方法在保持更快速度的同时，实现了比CurveLane-S方法更好的性能。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/1539e0f60c4d470697265bce4fe1c738.jpeg" width="70%" />
</div>

对于LLAMAS数据集，我们在表10中展示了结果。可以看出，我们的方法也实现了最佳性能和最快速度。

我们的方法在四个数据集上的可视化结果分别在图13和图14中展示。我们可以看到，所提出的混合锚点和我们的方法在各种条件下都表现良好。

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/70ef3328ff1f487aaccd1f16c0401bae.jpeg" width="70%" />
</div>

<div align=center>
  <img src="https://img-blog.csdnimg.cn/direct/cd22ca7f92b3481a8e09ead4212ed25e.jpeg" width="70%" />
</div>

# 结论

在本文中，我们提出了一种新颖的公式，结合混合锚系统和序数分类流水线，以实现卓越的速度和准确性。所提出的公式将车道检测视为直接在全局特征基础上，通过自顶向下的分类学习混合锚系统上的稀疏坐标。通过(这种方式，效率和无视觉线索的问题可以有效地得到解决。通过定性和定量实验，证明了所提出的混合锚系统和序数分类损失的有效性。特别是，我们方法的一个轻量级ResNet-18版本甚至能够达到每秒300帧以上（FPS）。

然而，我们方法也存在一些弱点，即锚点的布局，例如设置多少锚点以及在哪里放置锚点，仍然是固定的和手工制作的。自动的、动态的、可旋转的和非均匀的锚点将是更强大甚至更快方法的潜在方向。
